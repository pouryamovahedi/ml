{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - leading up to presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data into dataframes from the CSV.\n",
    "\n",
    "# Only useful for converting circuitIds to names\n",
    "df_circuits = pd.read_csv(\"data/circuits.csv\")\n",
    "df_constructors = pd.read_csv(\"data/constructors.csv\")\n",
    "df_costructor_standings = pd.read_csv(\"data/constructor_standings.csv\")\n",
    "df_constructor_results = pd.read_csv(\"data/constructor_results.csv\")\n",
    "# Only useful for converting IDs to names.\n",
    "df_drivers = pd.read_csv(\"data/drivers.csv\")\n",
    "df_driver_standings = pd.read_csv(\"data/driver_standings.csv\")\n",
    "df_lap_times = pd.read_csv(\"data/lap_times.csv\")\n",
    "df_pit_stops = pd.read_csv(\"data/pit_stops.csv\")\n",
    "df_qualifying = pd.read_csv(\"data/qualifying.csv\")\n",
    "df_races = pd.read_csv(\"data/races.csv\")\n",
    "df_results = pd.read_csv(\"data/results.csv\")\n",
    "# Status of race - usefull for seeing how racers ended a race.\n",
    "df_status = pd.read_csv(\"data/status.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove information that does not tell us anything interesting.\n",
    "df_circuits = df_circuits.drop(columns=[\n",
    "    \"lat\",\n",
    "    \"lng\", \n",
    "    \"alt\", \n",
    "    \"url\"])\n",
    "df_drivers = df_drivers.drop(columns=[\n",
    "    \"number\",\n",
    "    \"url\"])\n",
    "df_races = df_races.drop(columns=[\n",
    "    \"url\",\n",
    "    \"fp1_date\",\n",
    "    \"fp1_time\",\n",
    "    \"fp2_date\",\n",
    "    \"fp2_time\",\n",
    "    \"fp3_date\",\n",
    "    \"fp3_time\",\n",
    "    \"quali_date\",\n",
    "    \"quali_time\",\n",
    "    \"sprint_date\",\n",
    "    \"sprint_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status(df_status, df_results, index: int) -> str:\n",
    "    statusId = df_results.iloc[index - 1][\"statusId\"]\n",
    "    status = df_status.iloc[statusId - 1]\n",
    "    return status\n",
    "\n",
    "def get_drivers(df_drivers, df_results, raceId):\n",
    "    res = df_results[df_results[\"raceId\"] == raceId]\n",
    "    drivers = df_drivers.iloc[res[\"driverId\"] - 1]\n",
    "    return drivers\n",
    "\n",
    "# Races past certain year\n",
    "# TODO check if working?\n",
    "def get_recent_races(df_races, df_results, min_year):\n",
    "    races = df_races[df_races[\"year\"] >= min_year]\n",
    "    drivers = df_results[races[\"raceId\"]]\n",
    "    return drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_status(df_status, df_results, 1)\n",
    "#get_drivers(df_drivers, df_results, 1)\n",
    "#df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where \"position\" is empty\n",
    "# NOTE: Should this have been done after creating \"merge_attempt\"?\n",
    "df_results.drop(df_results[df_results[\"position\"] == \"\\\\N\"].index, inplace=True)\n",
    "# No results captured for the 2023 season, so use 2022.\n",
    "df_modify = df_results[df_results[\"raceId\"].isin(df_races[df_races[\"year\"] >= 2022][\"raceId\"].values)]\n",
    "# Remove additional useless columns\n",
    "df_prep = df_modify.drop(columns=[\"resultId\",\"number\", \"positionText\", \"fastestLap\"])\n",
    "# Convert Lap time from time to float, eg: \"1:00:00\" to \"60.00\" so that it can be used\n",
    "df_prep[\"fastestLapTime_seconds\"] = df_prep[\"fastestLapTime\"].apply(lambda x: float(x.split(':')[0])*60+float(x.split(':')[1]))\n",
    "\n",
    "df_qualifying[(df_qualifying[\"raceId\"] == 18) & (df_qualifying[\"driverId\"] == 1)][[\"position\", \"q1\", \"q2\", \"q3\"]]\n",
    "merge_attempt = pd.merge(df_prep, df_qualifying[[\"raceId\",\"driverId\", \"position\", \"q1\", \"q2\", \"q3\"]], on=[\"raceId\", \"driverId\"])\n",
    "\n",
    "# Remove rows where \"q1\", \"q2\", \"q3\" are empty\n",
    "merge_attempt = merge_attempt.dropna(subset=[\"q1\",\"q2\",\"q3\"])\n",
    "merge_attempt.drop(merge_attempt[merge_attempt[\"q1\"] == \"\\\\N\"].index, inplace=True)\n",
    "merge_attempt.drop(merge_attempt[merge_attempt[\"q2\"] == \"\\\\N\"].index, inplace=True)\n",
    "merge_attempt.drop(merge_attempt[merge_attempt[\"q3\"] == \"\\\\N\"].index, inplace=True)\n",
    "\n",
    "# More converting time to floats\n",
    "merge_attempt[\"q1s\"] = merge_attempt[\"q1\"].apply(lambda x: float(x.split(':')[0])*60+float(x.split(':')[1]))\n",
    "merge_attempt[\"q2s\"] = merge_attempt[\"q2\"].apply(lambda x: float(x.split(':')[0])*60+float(x.split(':')[1]))\n",
    "merge_attempt[\"q3s\"] = merge_attempt[\"q3\"].apply(lambda x: float(x.split(':')[0])*60+float(x.split(':')[1]))\n",
    "\n",
    "# Convert fastestLapSpeed from \"object\" to \"numeric\" -> required for classification.\n",
    "merge_attempt[\"fastestLapSpeed\"] = pd.to_numeric(merge_attempt[\"fastestLapSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(df_prep[\"grid\"], df_prep[\"position\"])\n",
    "#plt.scatter(df_prep[\"fastestLapTime_seconds\"], df_prep[\"grid\"])\n",
    "\n",
    "# # Initial Test\n",
    "# X = df_prep[\"grid\"]\n",
    "# y = df_prep[\"position\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# X_train = X_train.values.reshape(-1,1)\n",
    "# y_train = y_train.values.reshape(-1,)\n",
    "\n",
    "# X_test = X_test.values.reshape(-1,1)\n",
    "# y_test = y_test.values.reshape(-1,)\n",
    "\n",
    "# model = KNeighborsClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_attempt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_fit_train(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "    except:\n",
    "        # Naive Bayes fails for some reason, so catch the exception it causes\n",
    "        # and just assign a defualt value.\n",
    "        mae = 9999 \n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    GaussianNB(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(), # Currently does not converge and will show a warning when run.\n",
    "]\n",
    "\n",
    "X = merge_attempt[[\"grid\", \"position_y\", \"fastestLapSpeed\", \"fastestLapTime_seconds\", \"q1s\", \"q2s\", \"q3s\"]]\n",
    "y = merge_attempt[\"position_x\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.values.reshape(-1,)\n",
    "y_test = y_test.values.reshape(-1,)\n",
    "\n",
    "for model in classifiers:\n",
    "    print(f\"====== {model.__class__.__name__} =======\")\n",
    "    classifier_fit_train(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: See when we have no information of actual race results\n",
    "# X = merge_attempt[[\"grid\", \"position_y\", \"q1s\", \"q2s\", \"q3s\"]]\n",
    "# y = merge_attempt[\"fastestLapTime_seconds\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_fit_train(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"RMSE:\", sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"MAE\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"R2\", r2_score(y_test, y_pred))\n",
    "\n",
    "regressors = [\n",
    "    KNeighborsRegressor(),\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    DecisionTreeRegressor(),\n",
    "    SVR(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "print(\"\\nFastest Lap Time\\n\")\n",
    "\n",
    "X = merge_attempt[[\"grid\", \"position_x\", \"position_y\", \"fastestLapSpeed\", \"q1s\", \"q2s\", \"q3s\"]]\n",
    "y = merge_attempt[\"fastestLapTime_seconds\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train = y_train.values.reshape(-1,)\n",
    "y_test = y_test.values.reshape(-1,)\n",
    "\n",
    "for model in regressors:\n",
    "    print(f\"====== {model.__class__.__name__} =======\")\n",
    "    regressor_fit_train(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "print(\"\\nFastest Lap Speed\\n\")\n",
    "\n",
    "X = merge_attempt[[\"grid\", \"position_x\", \"position_y\", \"fastestLapTime_seconds\", \"q1s\", \"q2s\", \"q3s\"]]\n",
    "y = merge_attempt[\"fastestLapSpeed\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train = y_train.values.reshape(-1,)\n",
    "y_test = y_test.values.reshape(-1,)\n",
    "\n",
    "for model in regressors:\n",
    "    print(f\"====== {model.__class__.__name__} =======\")\n",
    "    regressor_fit_train(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
